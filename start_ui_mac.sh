#!/bin/bash
# DATASAM2GETé¡¹ç›®Macç‰ˆå¯åŠ¨è„šæœ¬

# æ¿€æ´»condaç¯å¢ƒ
source $(conda info --base)/etc/profile.d/conda.sh
conda activate datasam2get

echo "ğŸ¯ DATASAM2GETé¡¹ç›®å¯åŠ¨ (Macç‰ˆæœ¬)"
echo "é€‰æ‹©è¦å¯åŠ¨çš„åº”ç”¨:"
echo "1. æ•°æ®æ ‡æ³¨å·¥å…· (data_generation)"
echo "2. æ¨¡å‹è®­ç»ƒå·¥å…· (training_models)"
echo "3. YOLO-SAM2æ¼”ç¤º (demo_apps)"
echo "4. æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€"

read -p "è¯·è¾“å…¥é€‰æ‹© (1-4): " choice

case $choice in
    1)
        echo "ğŸ·ï¸  å¯åŠ¨æ•°æ®æ ‡æ³¨å·¥å…·..."
        cd data_generation
        streamlit run streamlit_app_enhanced.py --server.port 8501
        ;;
    2)
        echo "ğŸ“ å¯åŠ¨æ¨¡å‹è®­ç»ƒ..."
        cd training_models
        python run_training.py
        ;;
    3)
        echo "ğŸ® å¯åŠ¨YOLO-SAM2æ¼”ç¤º..."
        cd demo_apps
        python run_yolo_sam2_ui.py
        ;;
    4)
        echo "ğŸ–¥ï¸  ç³»ç»ŸçŠ¶æ€ä¿¡æ¯:"
        python -c "
import torch, platform
print(f'ç³»ç»Ÿ: {platform.system()} {platform.release()}')
print(f'å¤„ç†å™¨: {platform.processor()}')
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'CPUçº¿ç¨‹æ•°: {torch.get_num_threads()}')
if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    print('âœ… MPSåŠ é€Ÿå¯ç”¨ (Apple Silicon)')
else:
    print('â„¹ï¸  ä½¿ç”¨CPUå¤„ç†')
"
        ;;
    *)
        echo "âŒ æ— æ•ˆé€‰æ‹©"
        ;;
esac
