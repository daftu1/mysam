import os
# ç§»é™¤CPUå¼ºåˆ¶è®¾ç½®ï¼Œæ”¹ä¸ºGPUç‰ˆæœ¬
# os.environ["TORCHINDUCTOR_DISABLE"] = "1"
# os.environ["TORCH_COMPILE_DISABLE"] = "1"

import uuid
import shutil
import numpy as np
import cv2
import streamlit as st

st.set_page_config(layout="wide")
from PIL import Image
import torch
from moviepy import VideoFileClip
from torchvision.ops import masks_to_boxes
from sam2.build_sam import build_sam2_video_predictor
from streamlit_image_coordinates import streamlit_image_coordinates
import contextlib

# åˆå§‹åŒ–æ¨¡å‹
@st.cache_resource
def load_sam2_model():
    checkpoint = os.path.join(os.path.expanduser("~"), "sam2", "checkpoints", "sam2.1_hiera_base_plus.pt")
    model_cfg = os.path.join("configs", "sam2.1", "sam2.1_hiera_b+.yaml")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # æ”¹ä¸ºGPUç‰ˆæœ¬
    return build_sam2_video_predictor(model_cfg, checkpoint, device=device, vos_optimized=True)

sam2_model = load_sam2_model()

st.title("ğŸ¬ SAM2 æ™ºèƒ½è§†é¢‘æ ‡æ³¨å·¥å…· & YOLO11æ ¼å¼å¯¼å‡º")

VIDEO_DIR = "video_segments"
os.makedirs(VIDEO_DIR, exist_ok=True)

# ä¸Šä¼ è§†é¢‘
uploaded_video = st.file_uploader("ğŸ“ ä¸Šä¼ å®Œæ•´åŸå§‹è§†é¢‘", type=["mp4"])
if uploaded_video:
    original_path = "temp_uploaded.mp4"
    with open(original_path, "wb") as f:
        f.write(uploaded_video.read())

    cap = cv2.VideoCapture(original_path)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    duration = frame_count // fps
    st.video(original_path)

    st.subheader("âœ‚ï¸ è§†é¢‘è£å‰ª")
    start_time = st.slider("èµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰", 0, duration - 1, 0)
    end_time = st.slider("ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰", start_time + 1, duration, start_time + 5)

    if st.button("è£å‰ªå¹¶ä¿å­˜ç‰‡æ®µ"):
        clip = VideoFileClip(original_path).subclip(start_time, end_time)
        session_id = uuid.uuid4().hex[:8]
        segment_path = os.path.join(VIDEO_DIR, f"{session_id}.mp4")
        clip.write_videofile(segment_path, codec="libx264")
        st.success(f"âœ… è§†é¢‘è£å‰ªå®Œæˆ: {segment_path}")
        st.session_state["segment_path"] = segment_path
        st.session_state["session_id"] = session_id
        cap.release()
        shutil.move(original_path, f"{original_path}.bak")

# è§†é¢‘æ‹†å¸§ + åŠ è½½çŠ¶æ€
session_id = st.session_state.get("session_id", None)
segment_path = st.session_state.get("segment_path", None)

if session_id and segment_path:
    FRAME_DIR = f"frame_cache_{session_id}"
    os.makedirs(FRAME_DIR, exist_ok=True)

    if not os.listdir(FRAME_DIR):
        cap = cv2.VideoCapture(segment_path)
        frame_idx = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame_path = os.path.join(FRAME_DIR, f"{frame_idx:04d}.jpg")
            cv2.imwrite(frame_path, frame)
            frame_idx += 1
        cap.release()
        st.success(f"âœ… å…±æå– {frame_idx} å¸§è‡³ç¼“å­˜ç›®å½• {FRAME_DIR}")

    frame_files = sorted(os.listdir(FRAME_DIR))
    
    # æ·»åŠ å·¥ä½œæ¨¡å¼é€‰æ‹©
    st.subheader("ğŸ”§ å·¥ä½œæ¨¡å¼é€‰æ‹©")
    work_mode = st.radio("é€‰æ‹©å·¥ä½œæ¨¡å¼", ["åˆå§‹æ ‡æ³¨", "é¢„è§ˆ100å¸§æ©ç ", "ä¿®æ­£ç‰¹å®šå¸§"], horizontal=True)
    
    if work_mode == "åˆå§‹æ ‡æ³¨":
        frame_index = st.session_state.get("frame_index", 0)
        current_frame_path = os.path.join(FRAME_DIR, frame_files[frame_index])
        current_img = Image.open(current_frame_path)

        frame_np = np.array(current_img.convert("RGB"))
        if "overlay_map" in st.session_state and frame_index in st.session_state["overlay_map"]:
            preview_img = st.session_state["overlay_map"][frame_index]
        else:
            preview_img = frame_np.copy()

        points = st.session_state.get("points", {}).get(frame_index, [])
        for x, y, l in points:
            color = (0, 255, 0) if l == 1 else (0, 0, 255)
            cv2.circle(preview_img, (int(x), int(y)), 5, color, -1)

        # å·¦å›¾å³æ§
        col1, col2 = st.columns([3, 1])

        with col1:
            # é¢„è§ˆå¸§å¹¶ç‚¹å‡»æ‰“ç‚¹
            click = streamlit_image_coordinates(preview_img, key=f"frame_{frame_index}_{st.session_state.get('refresh_flag', False)}")
            st.image(preview_img, caption=f"ç‚¹å‡»å¸§æ·»åŠ ç‚¹ï¼Œå½“å‰å¸§: {frame_index}")
            if click:
                if "points" not in st.session_state:
                    st.session_state["points"] = {}
                if frame_index not in st.session_state["points"]:
                    st.session_state["points"][frame_index] = []
                # è®°å½•å½“å‰ç‚¹å‡»åæ ‡ï¼Œç­‰å¾…ç”¨æˆ·é€‰æ‹©æ­£/è´Ÿç‚¹
                st.session_state["last_click"] = (click["x"], click["y"])

        with col2:
            st.markdown("### ğŸï¸ å½“å‰å¸§æ§åˆ¶")
            frame_index = st.slider("å¸§ä½ç½®", 0, len(frame_files) - 1, value=frame_index, key="frame_index")
            st.write(f"å½“å‰å¸§ç¼–å·ï¼š**{frame_index}**")

            # æ ‡ç­¾ç®¡ç†
            st.subheader("ğŸ·ï¸ æ ‡ç­¾è¾“å…¥ä¸ç¡®è®¤")
            if "label_history" not in st.session_state:
                st.session_state["label_history"] = []
            label_input = st.text_input("âœï¸ è¾“å…¥æ ‡ç­¾å", value="", placeholder="e.g. çŒªè‚‰")
            if label_input:
                suggestions = [l for l in st.session_state["label_history"] if l.startswith(label_input.lower())]
                if suggestions:
                    st.markdown("ğŸ” è‡ªåŠ¨è¡¥å…¨å»ºè®®ï¼š" + ", ".join(suggestions[:5]))

            if st.button("âœ… ç¡®å®šæ ‡ç­¾"):
                label = label_input.strip().lower()
                if label:
                    if label not in st.session_state["label_history"]:
                        st.session_state["label_history"].append(label)
                    st.session_state["current_label"] = label
                    st.success(f"âœ… å½“å‰ä½¿ç”¨æ ‡ç­¾ï¼š`{label}`")
                else:
                    st.warning("âš ï¸ æ ‡ç­¾ä¸èƒ½ä¸ºç©º")

            label = st.session_state.get("current_label", None)

            # æ–°å¢ï¼šä¿ç•™ç‚¹/å»é™¤ç‚¹æŒ‰é’®ï¼Œç‚¹å‡»åå°†ä¸Šæ¬¡ç‚¹å‡»çš„ç‚¹åŠ å…¥points
            if "last_click" in st.session_state:
                if st.button("ä¿ç•™ç‚¹(æ­£ç‚¹)"):
                    if frame_index not in st.session_state["points"]:
                        st.session_state["points"][frame_index] = []
                    st.session_state["points"][frame_index].append((*st.session_state["last_click"], 1))
                    st.session_state["refresh_flag"] = not st.session_state.get("refresh_flag", False)
                    del st.session_state["last_click"]
                if st.button("å»é™¤ç‚¹(è´Ÿç‚¹)"):
                    if frame_index not in st.session_state["points"]:
                        st.session_state["points"][frame_index] = []
                    st.session_state["points"][frame_index].append((*st.session_state["last_click"], 0))
                    st.session_state["refresh_flag"] = not st.session_state.get("refresh_flag", False)
                    del st.session_state["last_click"]

            if st.button("ğŸ§¹ æ¸…é™¤å½“å‰å¸§æ‰€æœ‰ç‚¹"):
                if "points" in st.session_state and frame_index in st.session_state["points"]:
                    st.session_state["points"][frame_index] = []
                    if "overlay_map" in st.session_state and frame_index in st.session_state["overlay_map"]:
                        del st.session_state["overlay_map"][frame_index]
                    st.success("âœ… å½“å‰å¸§ç‚¹æ¸…é™¤å®Œæ¯•")
                    st.session_state["refresh_flag"] = not st.session_state.get("refresh_flag", False)

            if st.button("ğŸ§¼ æ¸…é™¤æ‰€æœ‰å¸§çš„ç‚¹"):
                st.session_state["points"] = {}
                if "overlay_map" in st.session_state:
                    st.session_state["overlay_map"] = {}
                st.success("âœ… æ‰€æœ‰å¸§ç‚¹æ¸…é™¤å®Œæ¯•")
                st.session_state["refresh_flag"] = not st.session_state.get("refresh_flag", False)

            if st.button("ğŸ‘ï¸ é¢„è§ˆå½“å‰å¸§æ ‡æ³¨"):
                if not points:
                    st.warning("âš ï¸ å½“å‰å¸§æ— ç‚¹å‡»ç‚¹")
                else:
                    pts = []
                    lbls = []
                    for x, y, l in points:
                        pts.append([x, y])
                        lbls.append(l)
                    with torch.autocast("cuda" if torch.cuda.is_available() else "cpu"):
                        inference_state = sam2_model.init_state(segment_path)
                        frame_idx, obj_ids, masks = sam2_model.add_new_points_or_box(
                            inference_state=inference_state,
                            frame_idx=frame_index,
                            obj_id=0,
                            points=pts,
                            labels=lbls,
                            clear_old_points=True,
                            normalize_coords=False
                        )
                        mask = masks[0, 0].cpu().numpy().astype(np.uint8)
                        if mask.sum() > 0:  # ä¿®å¤ï¼šæ£€æŸ¥æ©ç æ˜¯å¦æœ‰å‰æ™¯
                            box = masks_to_boxes(torch.tensor(mask[None]))[0].int().tolist()
                            x1, y1, x2, y2 = box
                            overlay = frame_np.copy()
                            overlay[mask == 1] = (overlay[mask == 1] * 0.5 + np.array([128, 128, 255]) * 0.5).astype(np.uint8)
                            for x, y, l in points:
                                cv2.circle(overlay, (int(x), int(y)), 5, (0,255,0) if l==1 else (0,0,255), -1)
                            cv2.rectangle(overlay, (x1, y1), (x2, y2), (0,255,0), 2)
                            st.image(overlay, caption=f"æ ‡ç­¾: {label} | ç‚¹æ•°: {len(points)} | BBox: {box}")
                            if label is not None and label in st.session_state["label_history"]:
                                label_id = st.session_state["label_history"].index(label)
                                save_dir = f"yolo_labels_{session_id}"
                                os.makedirs(save_dir, exist_ok=True)
                                h, w = mask.shape
                                yolo_line = f"{label_id} {(x1+x2)/2/w:.6f} {(y1+y2)/2/h:.6f} {(x2-x1)/w:.6f} {(y2-y1)/h:.6f}\n"
                                label_file = os.path.join(save_dir, frame_files[frame_index].replace(".jpg", ".txt"))
                                with open(label_file, "w") as f:
                                    f.write(yolo_line)
                                st.success(f"âœ… å•å¸§æ ‡ç­¾ä¿å­˜æˆåŠŸ: {label_file}")
                        else:
                            st.warning("âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ©ç ")

            if st.button("âš¡ ç”Ÿæˆ100å¸§æ©ç "):
                ref_points = st.session_state["points"].get(frame_index, [])
                if not ref_points or not label:
                    st.warning("âš ï¸ é¦–å¸§æœªæ‰“ç‚¹æˆ–æ ‡ç­¾æœªè®¾ç½®")
                else:
                    with torch.autocast("cuda" if torch.cuda.is_available() else "cpu"):
                        inference_state = sam2_model.init_state(segment_path)
                        pts = [[p[0], p[1]] for p in ref_points]
                        lbls = [p[2] for p in ref_points]
                        sam2_model.add_new_points_or_box(
                            inference_state=inference_state,
                            frame_idx=0,
                            obj_id=0,
                            points=pts,
                            labels=lbls,
                            clear_old_points=True,
                            normalize_coords=False
                        )
                        # æ‰¹é‡ä¼ æ’­
                        video_segments = {}
                        for out_frame_idx, out_obj_ids, out_mask_logits in sam2_model.propagate_in_video(inference_state):
                            video_segments[out_frame_idx] = {
                                out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()
                                for i, out_obj_id in enumerate(out_obj_ids)
                            }
                        st.session_state["video_segments"] = video_segments
                        st.session_state["inference_state"] = inference_state
                        st.success("âœ… 100å¸§æ©ç ç”Ÿæˆå®Œæˆï¼Œè¯·åˆ‡æ¢åˆ°'é¢„è§ˆ100å¸§æ©ç 'æ¨¡å¼æŸ¥çœ‹")

    elif work_mode == "é¢„è§ˆ100å¸§æ©ç ":
        if "video_segments" not in st.session_state:
            st.warning("âš ï¸ è¯·å…ˆåœ¨'åˆå§‹æ ‡æ³¨'æ¨¡å¼ä¸‹ç”Ÿæˆ100å¸§æ©ç ")
        else:
            st.subheader("ğŸï¸ 100å¸§æ©ç é¢„è§ˆ")
            preview_frame_idx = st.slider("é¢„è§ˆå¸§ä½ç½®", 0, min(len(frame_files)-1, 99), 0, key="preview_frame_idx")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                frame_path = os.path.join(FRAME_DIR, frame_files[preview_frame_idx])
                img = np.array(Image.open(frame_path).convert("RGB"))
                
                video_segments = st.session_state["video_segments"]
                mask = video_segments.get(preview_frame_idx, {}).get(0, None)
                
                if mask is not None and mask.sum() > 0:
                    overlay = img.copy()
                    overlay[mask == 1] = (overlay[mask == 1] * 0.5 + np.array([128,128,255]) * 0.5).astype(np.uint8)
                    box = masks_to_boxes(torch.tensor(mask[None]))[0].int().tolist()
                    x1, y1, x2, y2 = box
                    cv2.rectangle(overlay, (x1, y1), (x2, y2), (0,255,0), 2)
                    st.image(overlay, caption=f"å¸§ {preview_frame_idx} - æ©ç é¢„è§ˆ")
                else:
                    st.image(img, caption=f"å¸§ {preview_frame_idx} - æ— æ©ç ")
            
            with col2:
                st.markdown("### ğŸ”§ æ“ä½œé€‰é¡¹")
                if st.button("é€‰æ‹©æ­¤å¸§è¿›è¡Œä¿®æ­£"):
                    st.session_state["refine_frame_idx"] = preview_frame_idx
                    st.success(f"âœ… å·²é€‰æ‹©å¸§ {preview_frame_idx} è¿›è¡Œä¿®æ­£")
                
                label = st.session_state.get("current_label", "unknown")
                if st.button("ğŸ“¤ å¯¼å‡ºYOLO11æ ¼å¼"):
                    save_dir = f"yolo11_labels_{session_id}"
                    os.makedirs(save_dir, exist_ok=True)
                    
                    # ä¿å­˜classes.txt
                    with open(os.path.join(save_dir, "classes.txt"), "w") as f:
                        for i, label_name in enumerate(st.session_state.get("label_history", [])):
                            f.write(f"{label_name}\n")
                    
                    # ä¿å­˜æ¯å¸§çš„æ ‡æ³¨
                    exported_count = 0
                    for i, frame_file in enumerate(frame_files[:100]):  # é™åˆ¶100å¸§
                        mask = video_segments.get(i, {}).get(0, None)
                        if mask is not None and mask.sum() > 0:
                            box = masks_to_boxes(torch.tensor(mask[None]))[0].int().tolist()
                            x1, y1, x2, y2 = box
                            h, w = mask.shape
                            label_id = st.session_state["label_history"].index(label) if label in st.session_state["label_history"] else 0
                            yolo_line = f"{label_id} {(x1+x2)/2/w:.6f} {(y1+y2)/2/h:.6f} {(x2-x1)/w:.6f} {(y2-y1)/h:.6f}\n"
                            label_file = os.path.join(save_dir, frame_file.replace(".jpg", ".txt"))
                            with open(label_file, "w") as f:
                                f.write(yolo_line)
                            exported_count += 1
                    
                    st.success(f"âœ… YOLO11æ ¼å¼å¯¼å‡ºå®Œæˆï¼å…±å¯¼å‡º {exported_count} å¸§æ ‡æ³¨åˆ° {save_dir}")

    elif work_mode == "ä¿®æ­£ç‰¹å®šå¸§":
        if "refine_frame_idx" not in st.session_state:
            st.warning("âš ï¸ è¯·å…ˆåœ¨'é¢„è§ˆ100å¸§æ©ç 'æ¨¡å¼ä¸‹é€‰æ‹©è¦ä¿®æ­£çš„å¸§")
        else:
            refine_frame_idx = st.session_state["refine_frame_idx"]
            st.subheader(f"ğŸ”§ ä¿®æ­£å¸§ {refine_frame_idx}")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                frame_path = os.path.join(FRAME_DIR, frame_files[refine_frame_idx])
                img = np.array(Image.open(frame_path).convert("RGB"))
                
                # æ˜¾ç¤ºå½“å‰æ©ç 
                video_segments = st.session_state.get("video_segments", {})
                mask = video_segments.get(refine_frame_idx, {}).get(0, None)
                
                if mask is not None and mask.sum() > 0:
                    overlay = img.copy()
                    overlay[mask == 1] = (overlay[mask == 1] * 0.5 + np.array([128,128,255]) * 0.5).astype(np.uint8)
                    
                    # æ˜¾ç¤ºä¿®æ­£ç‚¹
                    refine_points = st.session_state.get("refine_points", [])
                    for x, y, l in refine_points:
                        color = (0, 255, 0) if l == 1 else (0, 0, 255)
                        cv2.circle(overlay, (int(x), int(y)), 8, color, -1)
                    
                    click = streamlit_image_coordinates(overlay, key=f"refine_{refine_frame_idx}")
                    if click:
                        st.session_state["last_refine_click"] = (click["x"], click["y"])
                    
                    st.image(overlay, caption=f"ä¿®æ­£å¸§ {refine_frame_idx} - ç‚¹å‡»æ·»åŠ ä¿®æ­£ç‚¹")
                else:
                    st.image(img, caption=f"å¸§ {refine_frame_idx} - æ— æ©ç ")
            
            with col2:
                st.markdown("### ğŸ”§ ä¿®æ­£æ“ä½œ")
                
                if "last_refine_click" in st.session_state:
                    if st.button("æ·»åŠ æ­£ç‚¹ä¿®æ­£"):
                        if "refine_points" not in st.session_state:
                            st.session_state["refine_points"] = []
                        st.session_state["refine_points"].append((*st.session_state["last_refine_click"], 1))
                        del st.session_state["last_refine_click"]
                    
                    if st.button("æ·»åŠ è´Ÿç‚¹ä¿®æ­£"):
                        if "refine_points" not in st.session_state:
                            st.session_state["refine_points"] = []
                        st.session_state["refine_points"].append((*st.session_state["last_refine_click"], 0))
                        del st.session_state["last_refine_click"]
                
                if st.button("åº”ç”¨ä¿®æ­£å¹¶é‡æ–°ä¼ æ’­"):
                    refine_points = st.session_state.get("refine_points", [])
                    if refine_points:
                        with torch.autocast("cuda" if torch.cuda.is_available() else "cpu"):
                            inference_state = st.session_state["inference_state"]
                            pts = [[p[0], p[1]] for p in refine_points]
                            lbls = [p[2] for p in refine_points]
                            
                            # åœ¨æŒ‡å®šå¸§æ·»åŠ ä¿®æ­£ç‚¹
                            sam2_model.add_new_points_or_box(
                                inference_state=inference_state,
                                frame_idx=refine_frame_idx,
                                obj_id=0,
                                points=pts,
                                labels=lbls,
                                clear_old_points=False,
                                normalize_coords=False
                            )
                            
                            # é‡æ–°ä¼ æ’­
                            video_segments = {}
                            for out_frame_idx, out_obj_ids, out_mask_logits in sam2_model.propagate_in_video(inference_state):
                                video_segments[out_frame_idx] = {
                                    out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()
                                    for i, out_obj_id in enumerate(out_obj_ids)
                                }
                            
                            st.session_state["video_segments"] = video_segments
                            st.session_state["refine_points"] = []
                            st.success("âœ… ä¿®æ­£å®Œæˆå¹¶é‡æ–°ä¼ æ’­ï¼")
                    else:
                        st.warning("âš ï¸ è¯·å…ˆæ·»åŠ ä¿®æ­£ç‚¹")
                
                if st.button("æ¸…é™¤ä¿®æ­£ç‚¹"):
                    st.session_state["refine_points"] = []
                    st.success("âœ… ä¿®æ­£ç‚¹å·²æ¸…é™¤")
