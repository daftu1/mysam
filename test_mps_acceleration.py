#!/usr/bin/env python3
"""
MPSåŠ é€Ÿæ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•Apple Silicon Macçš„MPSåŠ é€Ÿæ•ˆæœ
"""

import torch
import time
import numpy as np

def test_device_performance():
    """æµ‹è¯•ä¸åŒè®¾å¤‡çš„æ€§èƒ½"""
    print("ğŸš€ Apple Silicon MPSåŠ é€Ÿæ€§èƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æµ‹å¯ç”¨è®¾å¤‡
    devices = []
    device_names = []
    
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        devices.append(torch.device("mps"))
        device_names.append("ğŸš€ Apple Silicon MPS")
    
    if torch.cuda.is_available():
        devices.append(torch.device("cuda"))
        device_names.append("ğŸš€ CUDA GPU")
    
    devices.append(torch.device("cpu"))
    device_names.append("ğŸ’» CPU")
    
    # æµ‹è¯•ä¸åŒå¤§å°çš„çŸ©é˜µè¿ç®—
    matrix_sizes = [512, 1024, 2048]
    
    print(f"æ£€æµ‹åˆ°è®¾å¤‡: {', '.join(device_names)}")
    print()
    
    for size in matrix_sizes:
        print(f"ğŸ“Š æµ‹è¯•çŸ©é˜µå¤§å°: {size}x{size}")
        print("-" * 30)
        
        for device, name in zip(devices, device_names):
            try:
                # é¢„çƒ­
                if device.type != "cpu":
                    x = torch.randn(100, 100).to(device)
                    y = torch.randn(100, 100).to(device)
                    _ = torch.mm(x, y)
                    if device.type == "mps":
                        torch.mps.synchronize()
                    elif device.type == "cuda":
                        torch.cuda.synchronize()
                
                # åˆ›å»ºæµ‹è¯•æ•°æ®
                x = torch.randn(size, size).to(device)
                y = torch.randn(size, size).to(device)
                
                # æµ‹è¯•çŸ©é˜µä¹˜æ³•
                start_time = time.time()
                for _ in range(10):  # é‡å¤10æ¬¡
                    z = torch.mm(x, y)
                
                # ç­‰å¾…è®¡ç®—å®Œæˆ
                if device.type == "mps":
                    torch.mps.synchronize()
                elif device.type == "cuda":
                    torch.cuda.synchronize()
                
                end_time = time.time()
                
                avg_time = (end_time - start_time) / 10
                print(f"{name}: {avg_time:.4f}ç§’/æ¬¡")
                
                # æ¸…ç†å†…å­˜
                del x, y, z
                if device.type == "mps":
                    torch.mps.empty_cache()
                elif device.type == "cuda":
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                print(f"{name}: é”™è¯¯ - {str(e)}")
        
        print()
    
    # æµ‹è¯•ç¥ç»ç½‘ç»œç›¸å…³æ“ä½œ
    print("ğŸ§  ç¥ç»ç½‘ç»œæ“ä½œæ€§èƒ½æµ‹è¯•")
    print("-" * 30)
    
    for device, name in zip(devices, device_names):
        try:
            # æ¨¡æ‹Ÿå·ç§¯æ“ä½œ
            batch_size = 32
            channels = 64
            height, width = 224, 224
            
            x = torch.randn(batch_size, channels, height, width).to(device)
            conv = torch.nn.Conv2d(channels, 128, 3, padding=1).to(device)
            
            start_time = time.time()
            for _ in range(5):
                y = conv(x)
                y = torch.relu(y)
            
            if device.type == "mps":
                torch.mps.synchronize()
            elif device.type == "cuda":
                torch.cuda.synchronize()
            
            end_time = time.time()
            avg_time = (end_time - start_time) / 5
            
            print(f"{name} å·ç§¯æ“ä½œ: {avg_time:.4f}ç§’/æ¬¡")
            
            # æ¸…ç†å†…å­˜
            del x, y, conv
            if device.type == "mps":
                torch.mps.empty_cache()
            elif device.type == "cuda":
                torch.cuda.empty_cache()
                
        except Exception as e:
            print(f"{name} å·ç§¯æ“ä½œ: é”™è¯¯ - {str(e)}")
    
    print()
    print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
    print()
    print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("â€¢ æ‚¨çš„Macæ”¯æŒMPSåŠ é€Ÿï¼Œæ¯”çº¯CPUå¿«å¾ˆå¤š")
        print("â€¢ SAM2æ¨¡å‹å·²è‡ªåŠ¨å¯ç”¨MPSåŠ é€Ÿ")
        print("â€¢ æ¨èå¤„ç†ä¸­ç­‰è§„æ¨¡çš„è§†é¢‘æ•°æ®")
    else:
        print("â€¢ ä½¿ç”¨CPUå¤„ç†ï¼Œå»ºè®®é™ä½è§†é¢‘åˆ†è¾¨ç‡")
        print("â€¢ è€ƒè™‘å‡å°‘å¤„ç†å¸§æ•°ä»¥æå‡é€Ÿåº¦")

if __name__ == "__main__":
    test_device_performance() 