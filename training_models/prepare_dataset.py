#!/usr/bin/env python3
"""
YOLO11æ•°æ®é›†å‡†å¤‡è„šæœ¬
å°†SAM2ç”Ÿæˆçš„æ ‡æ³¨æ•°æ®è½¬æ¢ä¸ºYOLO11è®­ç»ƒæ ¼å¼
"""

import os
import shutil
import random
from pathlib import Path
import yaml

def prepare_yolo_dataset(
    images_dir="frame_cache_4f2d1b14",
    labels_dir="yolo11_labels_4f2d1b14", 
    output_dir="yolo_dataset",
    train_ratio=0.8,
    val_ratio=0.2
):
    """
    å‡†å¤‡YOLO11æ•°æ®é›†
    
    Args:
        images_dir: å›¾åƒæ–‡ä»¶ç›®å½•
        labels_dir: æ ‡æ³¨æ–‡ä»¶ç›®å½•
        output_dir: è¾“å‡ºæ•°æ®é›†ç›®å½•
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
    """
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    dataset_path = Path(output_dir)
    dataset_path.mkdir(exist_ok=True)
    
    # åˆ›å»ºå­ç›®å½•
    for split in ['train', 'val']:
        (dataset_path / split / 'images').mkdir(parents=True, exist_ok=True)
        (dataset_path / split / 'labels').mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    images_path = Path(images_dir)
    image_files = list(images_path.glob("*.jpg"))
    
    # è¿‡æ»¤æœ‰å¯¹åº”æ ‡æ³¨æ–‡ä»¶çš„å›¾åƒ
    labels_path = Path(labels_dir)
    valid_files = []
    
    for img_file in image_files:
        label_file = labels_path / f"{img_file.stem}.txt"
        if label_file.exists():
            # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶æ˜¯å¦ä¸ºç©º
            if label_file.stat().st_size > 0:
                valid_files.append(img_file.stem)
    
    print(f"æ‰¾åˆ° {len(valid_files)} ä¸ªæœ‰æ•ˆçš„å›¾åƒ-æ ‡æ³¨å¯¹")
    
    # éšæœºæ‰“ä¹±æ–‡ä»¶åˆ—è¡¨
    random.shuffle(valid_files)
    
    # è®¡ç®—åˆ†å‰²ç‚¹
    train_count = int(len(valid_files) * train_ratio)
    val_count = len(valid_files) - train_count
    
    train_files = valid_files[:train_count]
    val_files = valid_files[train_count:]
    
    print(f"è®­ç»ƒé›†: {len(train_files)} ä¸ªæ–‡ä»¶")
    print(f"éªŒè¯é›†: {len(val_files)} ä¸ªæ–‡ä»¶")
    
    # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
    def copy_files(file_list, split):
        for filename in file_list:
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            src_img = images_path / f"{filename}.jpg"
            dst_img = dataset_path / split / 'images' / f"{filename}.jpg"
            shutil.copy2(src_img, dst_img)
            
            # å¤åˆ¶æ ‡æ³¨æ–‡ä»¶
            src_label = labels_path / f"{filename}.txt"
            dst_label = dataset_path / split / 'labels' / f"{filename}.txt"
            shutil.copy2(src_label, dst_label)
    
    copy_files(train_files, 'train')
    copy_files(val_files, 'val')
    
    # è¯»å–ç±»åˆ«ä¿¡æ¯
    classes_file = labels_path / "classes.txt"
    if classes_file.exists():
        with open(classes_file, 'r', encoding='utf-8') as f:
            classes = [line.strip() for line in f.readlines() if line.strip()]
    else:
        classes = ['lajiao']  # é»˜è®¤ç±»åˆ«
    
    # åˆ›å»ºYOLOé…ç½®æ–‡ä»¶
    config = {
        'path': str(dataset_path.absolute()),  # æ•°æ®é›†æ ¹ç›®å½•
        'train': 'train/images',  # è®­ç»ƒå›¾åƒç›®å½•ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        'val': 'val/images',      # éªŒè¯å›¾åƒç›®å½•ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        'nc': len(classes),       # ç±»åˆ«æ•°é‡
        'names': classes          # ç±»åˆ«åç§°åˆ—è¡¨
    }
    
    config_file = dataset_path / "data.yaml"
    with open(config_file, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"\nâœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼")
    print(f"ğŸ“ æ•°æ®é›†ç›®å½•: {dataset_path.absolute()}")
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {config_file.absolute()}")
    print(f"ğŸ·ï¸ ç±»åˆ«æ•°é‡: {len(classes)}")
    print(f"ğŸ·ï¸ ç±»åˆ«åˆ—è¡¨: {classes}")
    
    return str(dataset_path.absolute()), str(config_file.absolute())

if __name__ == "__main__":
    dataset_dir, config_file = prepare_yolo_dataset()
    print(f"\nğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
    print(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_file}") 